{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVTnGjlzo6zD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4000131483818592598\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9488779619071974591\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10445629484208856455\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11269973607\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17117721634373215810\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NW2EgyyEpllm"
   },
   "outputs": [],
   "source": [
    "lines= pd.read_table('train-300k-clean.tsv', names=['eng', 'mar'], sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbB5SbFx_DWe"
   },
   "outputs": [],
   "source": [
    "with open('test.txt', 'r') as f:\n",
    "  test_ru = f.readlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8sG8QldFGls"
   },
   "outputs": [],
   "source": [
    "test_ru_df = pd.DataFrame(list(zip(test_ru, ['.']*len(test_ru))), columns=['eng', 'mar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "mE2q2-c2FohU",
    "outputId": "7ce85ece-ea79-4b47-8827-d72f87e01669"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_start_ 8 . с учетом изложенного выше япония х...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_start_ 5 . вопервых , следует обеспечить боле...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_start_ ядерные технологии применялись для пов...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_start_ в . помощь в проведении выборов _end_\\n</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_start_ 21 . подчеркивает критическую значимос...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_start_ 4 . главными движущими силами благого ...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_start_ 5 . исходя из этой убежденности , я хо...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_start_ пункт 15 повестки дня _end_\\n</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_start_ заместители председателя ангола и испа...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_start_ 7 . мы приветствуем усилия , предприни...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng mar\n",
       "0  _start_ 8 . с учетом изложенного выше япония х...   .\n",
       "1  _start_ 5 . вопервых , следует обеспечить боле...   .\n",
       "2  _start_ ядерные технологии применялись для пов...   .\n",
       "3    _start_ в . помощь в проведении выборов _end_\\n   .\n",
       "4  _start_ 21 . подчеркивает критическую значимос...   .\n",
       "5  _start_ 4 . главными движущими силами благого ...   .\n",
       "6  _start_ 5 . исходя из этой убежденности , я хо...   .\n",
       "7              _start_ пункт 15 повестки дня _end_\\n   .\n",
       "8  _start_ заместители председателя ангола и испа...   .\n",
       "9  _start_ 7 . мы приветствуем усилия , предприни...   ."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ru_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noyec12zsvfv"
   },
   "outputs": [],
   "source": [
    "#lines = lines[:20000]\n",
    "#lines = lines.append(test_ru_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xnS7QRxCpqVP",
    "outputId": "247a2b9c-3109-446a-e8f5-52593cc4eaf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298853, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "QGaN-j_8qExE",
    "outputId": "e74c2ed9-5f6b-4fdf-ad91-3555bf676674"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_start_ однако даже с учетом роста цен , вы мо...</td>\n",
       "      <td>_start_ but even with the price raise , you ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_start_ услуги гида на весь маршрут путешестви...</td>\n",
       "      <td>_start_ guide services for the whole trip _end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_start_ теперь фильтры css поддерживают сложны...</td>\n",
       "      <td>_start_ css filters now enable advanced effect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_start_ вот почему коллекции находятся в левой...</td>\n",
       "      <td>_start_ collections appear in the left panel t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_start_ однако после новогодних каникул чуть м...</td>\n",
       "      <td>_start_ in early january , however , this some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng  \\\n",
       "0  _start_ однако даже с учетом роста цен , вы мо...   \n",
       "1  _start_ услуги гида на весь маршрут путешестви...   \n",
       "2  _start_ теперь фильтры css поддерживают сложны...   \n",
       "3  _start_ вот почему коллекции находятся в левой...   \n",
       "4  _start_ однако после новогодних каникул чуть м...   \n",
       "\n",
       "                                                 mar  \n",
       "0  _start_ but even with the price raise , you ca...  \n",
       "1    _start_ guide services for the whole trip _end_  \n",
       "2  _start_ css filters now enable advanced effect...  \n",
       "3  _start_ collections appear in the left panel t...  \n",
       "4  _start_ in early january , however , this some...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcM4IfTxp2AX"
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.mar=lines.mar.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.mar=lines.mar.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.mar=lines.mar.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "lines.eng = lines.eng.apply(lambda x : '_' + x + '_')\n",
    "lines.mar = lines.mar.apply(lambda x : '_' + x + '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "RW6d5Q35p2rN",
    "outputId": "12bfc6db-1bfa-49b9-8466-e820307d9612"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116349</th>\n",
       "      <td>_start том сказал что мэри худая end_</td>\n",
       "      <td>_start tom said that mary was thin end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182955</th>\n",
       "      <td>_start мы ели пиццу end_</td>\n",
       "      <td>_start we were eating pizza end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42198</th>\n",
       "      <td>_start позже когда набрала силу борьба за прав...</td>\n",
       "      <td>_start later on when struggle for white marble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145711</th>\n",
       "      <td>_start том не хотел ни у кого спрашивать дорог...</td>\n",
       "      <td>_start tom didn t want to ask anyone for direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267203</th>\n",
       "      <td>_start они со всем что принадлежало им живые с...</td>\n",
       "      <td>_start and they went down they and all that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19370</th>\n",
       "      <td>_start угроза нового антисемитизма end_</td>\n",
       "      <td>_start the threat of the new anti semitism end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120068</th>\n",
       "      <td>_start какая разница между астрономией и астро...</td>\n",
       "      <td>_start what s the difference between astronomy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225290</th>\n",
       "      <td>_start положи е на полку end_</td>\n",
       "      <td>_start put it on the shelf end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261621</th>\n",
       "      <td>_start организация ооо открытый код спб end_</td>\n",
       "      <td>_start organization ltd artec end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148801</th>\n",
       "      <td>_start том терпеливо выслушал мэри end_</td>\n",
       "      <td>_start tom patiently listened to mary end_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "116349              _start том сказал что мэри худая end_   \n",
       "182955                           _start мы ели пиццу end_   \n",
       "42198   _start позже когда набрала силу борьба за прав...   \n",
       "145711  _start том не хотел ни у кого спрашивать дорог...   \n",
       "267203  _start они со всем что принадлежало им живые с...   \n",
       "19370             _start угроза нового антисемитизма end_   \n",
       "120068  _start какая разница между астрономией и астро...   \n",
       "225290                      _start положи е на полку end_   \n",
       "261621       _start организация ооо открытый код спб end_   \n",
       "148801            _start том терпеливо выслушал мэри end_   \n",
       "\n",
       "                                                      mar  \n",
       "116349            _start tom said that mary was thin end_  \n",
       "182955                   _start we were eating pizza end_  \n",
       "42198   _start later on when struggle for white marble...  \n",
       "145711  _start tom didn t want to ask anyone for direc...  \n",
       "267203  _start and they went down they and all that th...  \n",
       "19370     _start the threat of the new anti semitism end_  \n",
       "120068  _start what s the difference between astronomy...  \n",
       "225290                    _start put it on the shelf end_  \n",
       "261621                 _start organization ltd artec end_  \n",
       "148801         _start tom patiently listened to mary end_  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "all_marathi_words=set()\n",
    "lenght_list=[]\n",
    "lenght_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhzEOeLnr2pk"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of English\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "# Vocabulary of French \n",
    "for mar in lines.mar:\n",
    "    for word in mar.split():\n",
    "        if word not in all_marathi_words:\n",
    "            all_marathi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z1zjRsbpr7XD",
    "outputId": "d6a82909-a545-4752-93d8-9f9206271dd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Max Length of source sequence\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GGLKg6wWr9HB",
    "outputId": "21820631-b645-4bdd-dc7b-7ec071f1f563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of target sequence\n",
    "for l in lines.mar:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O4ZPj3ICr__M",
    "outputId": "53a2d979-93f7-4f32-8e24-aececc3294e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158862, 67567)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_marathi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_marathi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4RSor73nsGWu",
    "outputId": "be79b9a0-456d-4ab0-cb3c-5acf7b2fd4d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67568"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "zZIY_DvfsIEH",
    "outputId": "15230ad0-759e-46e6-d979-1b6d2a4fad70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298843</th>\n",
       "      <td>_start создание этих рабочих групп было вызван...</td>\n",
       "      <td>_start the establishment of the task forces wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298844</th>\n",
       "      <td>_start доля организации объединенных наций a end_</td>\n",
       "      <td>_start united nations share a end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298845</th>\n",
       "      <td>_start было внесено предложение о возможных пу...</td>\n",
       "      <td>_start a proposal was made as to how this can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298846</th>\n",
       "      <td>_start марокко г н бенджелун туими end_</td>\n",
       "      <td>_start morocco mr benjelloun touimi end_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298847</th>\n",
       "      <td>_start в своем докладе кпк рекомендовал предст...</td>\n",
       "      <td>_start in its report cpc had recommended that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298848</th>\n",
       "      <td>_start продовольственные товары доставлялись м...</td>\n",
       "      <td>_start food commodities were shipped to monrov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298849</th>\n",
       "      <td>_start представитель заявила что женщины в сел...</td>\n",
       "      <td>_start the representative stated that women in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298850</th>\n",
       "      <td>_start как представляется процесс урбанизации ...</td>\n",
       "      <td>_start a three stage urbanization process can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298851</th>\n",
       "      <td>_start по состоянию на ноября года никакого от...</td>\n",
       "      <td>_start as at november no reply had been receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298852</th>\n",
       "      <td>_start просит далее генерального секретаря про...</td>\n",
       "      <td>_start further requests the secretary general ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "298843  _start создание этих рабочих групп было вызван...   \n",
       "298844  _start доля организации объединенных наций a end_   \n",
       "298845  _start было внесено предложение о возможных пу...   \n",
       "298846            _start марокко г н бенджелун туими end_   \n",
       "298847  _start в своем докладе кпк рекомендовал предст...   \n",
       "298848  _start продовольственные товары доставлялись м...   \n",
       "298849  _start представитель заявила что женщины в сел...   \n",
       "298850  _start как представляется процесс урбанизации ...   \n",
       "298851  _start по состоянию на ноября года никакого от...   \n",
       "298852  _start просит далее генерального секретаря про...   \n",
       "\n",
       "                                                      mar  \n",
       "298843  _start the establishment of the task forces wa...  \n",
       "298844                 _start united nations share a end_  \n",
       "298845  _start a proposal was made as to how this can ...  \n",
       "298846           _start morocco mr benjelloun touimi end_  \n",
       "298847  _start in its report cpc had recommended that ...  \n",
       "298848  _start food commodities were shipped to monrov...  \n",
       "298849  _start the representative stated that women in...  \n",
       "298850  _start a three stage urbanization process can ...  \n",
       "298851  _start as at november no reply had been receiv...  \n",
       "298852  _start further requests the secretary general ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "# lines = shuffle(lines)\n",
    "lines.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZmvYnG_zsL90",
    "outputId": "374c688a-82e7-41c6-8e91-09286b418678"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108000,), (12000,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "llen = len(lines)\n",
    "X, y = lines.eng[:120000], lines.mar[:120000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iN5GlWK9sOQn"
   },
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "\n",
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_len),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_len),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_len, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkKL58WWsQji"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens+1, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "\n",
    "# def loss_function(real, pred):\n",
    "#   mask = 1 - tf.equal(real, 0)\n",
    "#   loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "#   return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SL4bYz_JsWOB"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5u0WT8irsZJO",
    "outputId": "7037f18a-0c87-4913-a542-c71b3f2c90f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  10/2700 [..............................] - ETA: 1:53:18 - loss: 0.6548 - acc: 0.3171"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b714889cda31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n\u001b[1;32m      7\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 40\n",
    "epochs = 1\n",
    "\n",
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGLytc-axbd7"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rUs7AYlxcWu"
   },
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9v_LCcdos6Aw"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6OconLtuzWk"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    #target_seq[0, 0] = target_token_index['start_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_end' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9rwbtqXG_jq"
   },
   "outputs": [],
   "source": [
    "def sentence2idxs(input_text):\n",
    "  encoder_input_data = np.zeros(len(input_text))\n",
    "  for i, word in enumerate(input_text.split(' ')):\n",
    "    encoder_input_data[i] = input_token_index[word] # encoder input seq\n",
    "  return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ut6W7ozjHnxY",
    "outputId": "b6088d34-666e-4ac4-fae4-a42308ac9739"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000e+00, 4.3738e+04, 4.0620e+03, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = sentence2idxs('_start должность end_')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "seM0JIrdIMOB",
    "outputId": "3be6ee37-32f1-4768-86d4-e49607192897"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the same thing end_ end_ end_ end_ end_ end_ end_ end_'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "decode_sequence(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jc3Od1zxu2UL"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssoCw6X8vAu1"
   },
   "outputs": [],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VndC4TOA09xh",
    "outputId": "c2cf771e-7620-406e-fb0f-1a328b3c93e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: _start я показал ему дорогу end_\n",
      "Actual Marathi Translation:  i showed him the way \n",
      "Predicted Marathi Translation:  the i was hoping to find him end_ end_ end_ end_ \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Marathi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Marathi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wdNOcSsX0Wsa",
    "outputId": "9654be9b-d99d-497c-895b-fa86193242df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: _start далее апостол пишет end_\n",
      "Actual Marathi Translation:  the apostle continues \n",
      "Predicted Marathi Translation:  the people are going to get out of the morning \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Marathi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Marathi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UE2lu0w0hjl"
   },
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as out:\n",
    "  for line in lines[-500:]['eng']:\n",
    "    input_seq = sentence2idxs(line)\n",
    "    translated = decode_sequence(input_seq)\n",
    "    out.write(translated[:-4] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4piS3rzmLCeL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
